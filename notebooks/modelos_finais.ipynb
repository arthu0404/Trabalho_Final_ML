{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44ea453",
   "metadata": {},
   "source": [
    "## **Notebook com os Modelos finais**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3f282",
   "metadata": {},
   "source": [
    "**Autores:**\n",
    "\n",
    "- Arthur Brandão do Nascimento\n",
    "\n",
    "- Caio Ávila Paulo\n",
    "\n",
    "- Matheus Macedo do Nascimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f14d48",
   "metadata": {},
   "source": [
    "## **Introdução**\n",
    "Este notebook tem por objetivo implementar e comparar diferentes algoritmos de aprendizado de máquina supervisionado de classificação. A partir de características como composição, tamanho e tempo de exposição de diferentes materiais, será prevista sua toxicidade em relação a diferentes tipos de células.\n",
    "\n",
    "Os algoritmos utilizados serão os de k vizinhos mais próximos (knn), árvore de decisão, floresta aleatória, Support Vector Classifier (SVC) e Regressão Logística. O desempenho de cada um deles será estimado por validação cruzada do tipo k-fold e os hiperparâmetros dos modelos serão otimizados com o Optuna. Além disso, um modelo baseline será estabelecido para fins de comparação.\n",
    "\n",
    "O Optuna também será usado para testar a normalização dos dados. A métrica a ser otimizada será a f1-macro, adequada ao target categórico binário: a partir dos atributos tanto do material quanto da célula, será atribuído o rótulo \"tóxico\" ou \"não tóxico\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c83cb8",
   "metadata": {},
   "source": [
    "### **Importando as bibliotecas necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae229090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caio25002\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from optuna import create_study\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score_score\n",
    "from sklearn.metrics import recall_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8224d56",
   "metadata": {},
   "source": [
    "### **Importando o dataset**\n",
    "\n",
    "O dataset escolhido tem, a princípio, 3923 linhas e 17 colunas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91207d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3923, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material_type</th>\n",
       "      <th>Core_size</th>\n",
       "      <th>Hydro_size</th>\n",
       "      <th>Surface_charge</th>\n",
       "      <th>Surface_area</th>\n",
       "      <th>Formation_enthalpy</th>\n",
       "      <th>Conduction_band</th>\n",
       "      <th>Valence_band</th>\n",
       "      <th>Electronegativity</th>\n",
       "      <th>Assay</th>\n",
       "      <th>Cell_name</th>\n",
       "      <th>Cell_species</th>\n",
       "      <th>Cell_origin</th>\n",
       "      <th>Cell_type</th>\n",
       "      <th>Exposure_time</th>\n",
       "      <th>Exposure_dose</th>\n",
       "      <th>Toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Material_type  Core_size  Hydro_size  Surface_charge  Surface_area  \\\n",
       "0         Al2O3       39.7       267.0            36.3          64.7   \n",
       "1         Al2O3       39.7       267.0            36.3          64.7   \n",
       "2         Al2O3       39.7       267.0            36.3          64.7   \n",
       "3         Al2O3       39.7       267.0            36.3          64.7   \n",
       "4         Al2O3       39.7       267.0            36.3          64.7   \n",
       "\n",
       "   Formation_enthalpy  Conduction_band  Valence_band  Electronegativity Assay  \\\n",
       "0             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "1             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "2             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "3             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "4             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "\n",
       "  Cell_name Cell_species Cell_origin Cell_type  Exposure_time  Exposure_dose  \\\n",
       "0     HCMEC        Human       Blood    Normal           24.0          0.001   \n",
       "1     HCMEC        Human       Blood    Normal           24.0          0.010   \n",
       "2     HCMEC        Human       Blood    Normal           24.0          0.100   \n",
       "3     HCMEC        Human       Blood    Normal           24.0          1.000   \n",
       "4     HCMEC        Human       Blood    Normal           24.0          5.000   \n",
       "\n",
       "   Toxicity  \n",
       "0  Nontoxic  \n",
       "1  Nontoxic  \n",
       "2  Nontoxic  \n",
       "3  Nontoxic  \n",
       "4  Nontoxic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/dataset_nanotoxicologia_combinado.csv\")\n",
    "\n",
    "display(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b2540",
   "metadata": {},
   "source": [
    "### **Definindo as ``FEATURES`` e o ``TARGET``**\n",
    "\n",
    "As features serão separadas entre aquelas que já são valores numéricos (``FEATURES_NUM``) e aquelas que serão convertidas em valores binários (``FEATURES_DUMMY``).\n",
    "\n",
    "Variável alvo (**``TARGET``**):\n",
    "- ``\"Toxicity\"`` - se a substância, nas dadas condições, é tóxica ou não à célula informada nos atributos.\n",
    "\n",
    "Features Numéricas (**``FEATURES_NUM``**):\n",
    "\n",
    " - ``\"Core_size\"``, ``\"Hydro_size\"``, ``\"Surface_charge\"``, ``\"Surface_area\"``, ``\"Formation_enthalpy\"``, ``\"Conduction_band\"``, ``\"Valence_band\"``, ``\"Electronegativity\"`` - características físico-químicas do material analisado.\n",
    " \n",
    " - ``\"Exposure_time\"``, ``\"Exposure_dose\"`` - características da exposição da célula ao material.\n",
    "\n",
    "Features Categóricas (**``FEATURES_DUMMY``**):\n",
    "\n",
    "- ``\"Material_type\"`` - composição do material.\n",
    "\n",
    "- ``\"Assay\"``, ``\"Cell_name\"``, ``\"Cell_species\"``, ``\"Cell_origin\"``, ``\"Cell_type\"`` - características da célula exposta ao material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55751354",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_NUM = [\"Core_size\", \n",
    "                \"Hydro_size\", \n",
    "                \"Surface_charge\", \n",
    "                \"Surface_area\", \n",
    "                \"Formation_enthalpy\", \n",
    "                \"Conduction_band\", \n",
    "                \"Valence_band\", \n",
    "                \"Electronegativity\", \n",
    "                \"Exposure_time\", \n",
    "                \"Exposure_dose\"\n",
    "]\n",
    "\n",
    "FEATURES_DUMMY = [\"Material_type\", \"Assay\", \"Cell_name\", \"Cell_species\", \"Cell_origin\", \"Cell_type\"]\n",
    "\n",
    "TARGET = [\"Toxicity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a1da49",
   "metadata": {},
   "source": [
    "### **Evitando vazamento de dados pelo ``groupby()``**\n",
    "Pode ser que vários dados do dataset sejam iguais em todos os atributos, diferindo (ou não) apenas no target. Dessa forma, alguns desses dados poderiam acabar sendo usado na etapa de treino e outros na fase de teste. Isso faria com que a métrica não refletisse o real desempenho do modelo; afinal, ele já \"conheceria\" alguns dados de teste, o que acarreta uma previsão enviesada.\n",
    "\n",
    "Para evitar esse tipo de vazamento, *antes* do split de treino e teste, é necessário acabar com essa redundância. Isso é feito agrupando todos os dados duplicados em um só: os atributos continuam os mesmos, mas apenas um valor de target é utilizado, a partir de uma estatística dos dados originais. Como o target é categórico, será usada a moda.\n",
    "\n",
    "Importante que os dados duplicados não precisam ser cópias idênticas: se todos os atributos forem muito próximos (apesar de não serem iguais), o vazamento de dados ocorrerá da mesma maneira. Por isso, antes de identificar dados repetidos e agrupá-los, arredonda-se o valor de cada atributo em uma casa adequada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13d84b",
   "metadata": {},
   "source": [
    "#### **Arredondando**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5afe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3923, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casa_arredondamento = {\n",
    "    \"Core_size\": 0, \n",
    "    \"Hydro_size\": 0, \n",
    "    \"Surface_charge\": 0, \n",
    "    \"Surface_area\": 0, \n",
    "    \"Formation_enthalpy\": 0, \n",
    "    \"Conduction_band\": 0,\n",
    "    \"Valence_band\": 0, \n",
    "    \"Electronegativity\": 0, \n",
    "    \"Exposure_time\": 1, \n",
    "    \"Exposure_dose\": 1,\n",
    "}\n",
    "\n",
    "df_round = df.round(casa_arredondamento)\n",
    "\n",
    "df_round.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7a234",
   "metadata": {},
   "source": [
    "Como nós podemos ver pelo código abaixo esse dataset possui alguns dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb964f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas em df_round: 43\n"
     ]
    }
   ],
   "source": [
    "num_duplicados = df_round[FEATURES_NUM + FEATURES_DUMMY].duplicated().sum()\n",
    "print(f\"Número de linhas duplicadas em df_round: {num_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56d2ef",
   "metadata": {},
   "source": [
    "#### **Agrupando**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce360a28",
   "metadata": {},
   "source": [
    "O [``agg()``](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) é um método do pandas usado para aplicar uma ou mais operações de agregação em grupos de dados. Como o target (``\"Toxicity\"``) é categórico, usaremos a moda para decidir o rótulo daquele grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5173552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_moda(serie):\n",
    "    \"\"\"Calcula a moda de uma série\"\"\"\n",
    "    moda = serie.mode()\n",
    "    return moda[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6124a761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O shape (linhas x colunas) do df_round é: (3923, 17)\n",
      "O shape (linhas x colunas) do df_tratado é: (3880, 17)\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df_round.groupby(FEATURES_NUM + FEATURES_DUMMY, sort=False)\n",
    "\n",
    "agg_dict = {\n",
    "    **{col: \"mean\" for col in FEATURES_NUM},\n",
    "    **{col: calcular_moda for col in FEATURES_DUMMY},\n",
    "    \"Toxicity\": calcular_moda\n",
    "}\n",
    "\n",
    "df_grouped = df_grouped.agg(agg_dict)\n",
    "df_grouped = df_grouped.reset_index(drop=True)\n",
    "\n",
    "print(f\"O shape (linhas x colunas) do df_round é: {df_round.shape}\")\n",
    "print(f\"O shape (linhas x colunas) do df_tratado é: {df_grouped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b70b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas em df_grouped: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicados = df_grouped[FEATURES_NUM + FEATURES_DUMMY].duplicated().sum()\n",
    "print(f\"Número de linhas duplicadas em df_grouped: {num_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0d7ef",
   "metadata": {},
   "source": [
    "Como podemos ver não há mais valores duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d8933",
   "metadata": {},
   "source": [
    "### **Fazendo a codificação One-Hot**\n",
    "Os algoritmos de aprendizado de máquina utilizados exigem que todos os atributos sejam numéricos. Dessa forma, é necessário transformar os dados qualitativos adequadamente.  O codificador One-Hot transforma uma coluna de dados categóricos em várias colunas, cada qual representando um dos rótulos possíveis; se o dado originalmente tinha aquele rótulo, atribui-se o valor 1, caso contrário preenche-se com 0. Isso será feito com todos os ``\"FEATURES_DUMMY\"``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b40473a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3880, 203)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Core_size</th>\n",
       "      <th>Hydro_size</th>\n",
       "      <th>Surface_charge</th>\n",
       "      <th>Surface_area</th>\n",
       "      <th>Formation_enthalpy</th>\n",
       "      <th>Conduction_band</th>\n",
       "      <th>Valence_band</th>\n",
       "      <th>Electronegativity</th>\n",
       "      <th>Exposure_time</th>\n",
       "      <th>Exposure_dose</th>\n",
       "      <th>...</th>\n",
       "      <th>Cell_origin_Pancreas</th>\n",
       "      <th>Cell_origin_Plant cell</th>\n",
       "      <th>Cell_origin_Prostate</th>\n",
       "      <th>Cell_origin_Skin</th>\n",
       "      <th>Cell_origin_Stomach</th>\n",
       "      <th>Cell_origin_Tetis</th>\n",
       "      <th>Cell_origin_Tongue</th>\n",
       "      <th>Cell_origin_Umbilical vein</th>\n",
       "      <th>Cell_type_Cancer</th>\n",
       "      <th>Cell_type_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Core_size  Hydro_size  Surface_charge  Surface_area  Formation_enthalpy  \\\n",
       "0       40.0       267.0            36.0          65.0               -17.0   \n",
       "1       40.0       267.0            36.0          65.0               -17.0   \n",
       "2       40.0       267.0            36.0          65.0               -17.0   \n",
       "3       40.0       267.0            36.0          65.0               -17.0   \n",
       "4       40.0       267.0            36.0          65.0               -17.0   \n",
       "\n",
       "   Conduction_band  Valence_band  Electronegativity  Exposure_time  \\\n",
       "0             -2.0         -10.0                6.0           24.0   \n",
       "1             -2.0         -10.0                6.0           24.0   \n",
       "2             -2.0         -10.0                6.0           24.0   \n",
       "3             -2.0         -10.0                6.0           24.0   \n",
       "4             -2.0         -10.0                6.0           24.0   \n",
       "\n",
       "   Exposure_dose  ... Cell_origin_Pancreas  Cell_origin_Plant cell  \\\n",
       "0            0.0  ...                    0                       0   \n",
       "1            0.1  ...                    0                       0   \n",
       "2            1.0  ...                    0                       0   \n",
       "3            5.0  ...                    0                       0   \n",
       "4           10.0  ...                    0                       0   \n",
       "\n",
       "   Cell_origin_Prostate  Cell_origin_Skin  Cell_origin_Stomach  \\\n",
       "0                     0                 0                    0   \n",
       "1                     0                 0                    0   \n",
       "2                     0                 0                    0   \n",
       "3                     0                 0                    0   \n",
       "4                     0                 0                    0   \n",
       "\n",
       "   Cell_origin_Tetis  Cell_origin_Tongue  Cell_origin_Umbilical vein  \\\n",
       "0                  0                   0                           0   \n",
       "1                  0                   0                           0   \n",
       "2                  0                   0                           0   \n",
       "3                  0                   0                           0   \n",
       "4                  0                   0                           0   \n",
       "\n",
       "   Cell_type_Cancer  Cell_type_Normal  \n",
       "0                 0                 1  \n",
       "1                 0                 1  \n",
       "2                 0                 1  \n",
       "3                 0                 1  \n",
       "4                 0                 1  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, dtype=np.int32)\n",
    "dummy_encoded = encoder.fit_transform(df_grouped[FEATURES_DUMMY])\n",
    "\n",
    "dummy_columns = encoder.get_feature_names_out(FEATURES_DUMMY)\n",
    "df_dummy = pd.DataFrame(dummy_encoded, columns=dummy_columns, index=df_grouped.index)\n",
    "\n",
    "df_dummy = pd.concat([df_grouped[FEATURES_NUM + TARGET], df_dummy], axis=1)\n",
    "FEATURES_FINAL = FEATURES_NUM + list(dummy_columns)\n",
    "\n",
    "display(df_dummy.shape)\n",
    "display(df_dummy.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9e2c1",
   "metadata": {},
   "source": [
    "### **Definindo os dados de treino e de teste**\n",
    "Com o dataframe devidamente tratado, pode ser feita a divisão dos dados em teste e treino. No caso será utilizado o ``stratify`` pois há um certo desbalanço no dataset, havendo mais dados sobre nanopartículas não tóxicas do que nanopartículas tóxicas, o ``\"stratify\"`` mantém a proporção das classes em ambos os conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d1b08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TESTE = 0.25\n",
    "SEED = 404\n",
    "\n",
    "valores_target = df_dummy[TARGET].values.ravel()\n",
    "\n",
    "df_treino, df_teste = train_test_split(df_dummy, test_size=TAMANHO_TESTE, random_state=SEED, stratify=valores_target)\n",
    "\n",
    "X_teste = df_teste.reindex(FEATURES_FINAL, axis=1)\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "X_treino = df_treino.reindex(FEATURES_FINAL, axis=1)\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d5eb3",
   "metadata": {},
   "source": [
    "### **Criando os modelos e espaços de busca**\n",
    "\n",
    "Serão criados os seguintes modelos para comparação:\n",
    "\n",
    "- Baseline (DummyClassifier)\n",
    "- k-Nearest Neighbors classifier (KNN)\n",
    "- Árvore de Decisão\n",
    "- Floresta Aleatória\n",
    "- Regressão Logística\n",
    "- Support Vector Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c32d8",
   "metadata": {},
   "source": [
    "#### **Baseline**\n",
    "\n",
    "O baseline estabelece uma referência mínima de desempenho, onde qualquer modelo útil deve superar essa referência.\n",
    "\n",
    "No caso, foi utilizado o ``DummyClassifier(strategy='most_frequent')``, que prevê sempre a moda dos valores de y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0e5601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868144690781797"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "modelo_baseline.fit(X_treino, y_treino)\n",
    "y_prev_estimativa_baseline = modelo_baseline.predict(X_teste)\n",
    "\n",
    "f1_macro_estimativa_dummy = f1_score(y_teste, y_prev_estimativa_baseline, pos_label=\"Nontoxic\")\n",
    "f1_macro_estimativa_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7684c60",
   "metadata": {},
   "source": [
    "#### **Implementação dos Modelos com o Optuna**\n",
    "O Optuna é um framework de otimização de hiperparâmetros. Ele automatiza o processo de enontrar o conjunto ótimo de hiperparâmetros para um dado modelo, almejando minimizar ou maximizar uma função objetiva específica.\n",
    "\n",
    "No Optuna, os ``Trials`` são as tentativas com diferentes combinações de hiperparâmetros e o ``Study`` é o conjunto de trials para um determinado objetivo.\n",
    "\n",
    "Nesse contexto, a função ``cria_instancia_modelo`` serve para criar uma instância do modelo escolhido, recebendo um trial.\n",
    "Para definir o espaço do dicionário dos parâmetros é usado o ``trial.suggest_*()``.\n",
    "\n",
    "Além disso, foi utilizada a decisão de normalização dos dados como um hiperparâmetro adicional. Para isso foi criado um curto **pipeline** com o ``make_pipeline()``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112195a",
   "metadata": {},
   "source": [
    "#### **Instância K-NN**\n",
    "\n",
    "Baseado no princípio de que exemplos similares tendem a pertencer à mesma classe. Para classificar uma nova amostra, o algoritmo calcula as distâncias entre essa amostra e os pontos do conjunto de treinamento, identifica os K vizinhos mais próximos e realiza uma votação majoritária entre suas classes.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``n_neighbors``**: número de vizinhos\n",
    "\n",
    "- **``weights``**: uniform, sem pesos, ou distance, em que vizinhos mais próximos tem mais peso\n",
    "\n",
    "- **``p``**: tipo de distância, 1=Manhattan, 2=Euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb30db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_knn(trial):\n",
    "    \"\"\"Cria uma instância de um modelo KNN.\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"n_neighbors\": trial.suggest_int(\"num_vizinhos\", 1, 200, log=True),\n",
    "        \"weights\": trial.suggest_categorical(\"pesos\", [\"uniform\", \"distance\"]),\n",
    "        \"p\": trial.suggest_int(\"tipo_distancia\", 1, 2),\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_knn = make_pipeline(\n",
    "            normalizador,\n",
    "            KNeighborsClassifier(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_knn = KNeighborsClassifier(**parametros)\n",
    "\n",
    "    return modelo_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8830c",
   "metadata": {},
   "source": [
    "#### **Instância Árvore de Decisão**\n",
    "\n",
    "O algoritmo da árvore de decisão constrói uma estrutura similar a um fluxograma, onde cada nó interno representa uma decisão baseada em uma feature específica, cada ramo representa o resultado dessa decisão e cada nó folha representa a classe predita. O processo de construção da árvore segue uma estratégia que visa a máxima separação dos nós resultantes em cada divisão, utilizando critérios como entropia ou índice Gini para medir a homogeneidade das classes. A principal vantagem das árvores de decisão em relação às florestas aleatórias reside em sua alta interpretabilidade.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``max_depth``**: Profundidade máxima da árvore\n",
    "\n",
    "- **``criterion``**: A função usada para medir a qualidade de um _split_ em cada nó\n",
    "\n",
    "- **``min_samples_split``**: Número mínimo de amostras necessárias para dividir um nó\n",
    "\n",
    "- **``min_samples_leaf``**:  Número mínimo de amostras em um nó folha\n",
    "\n",
    "- **``max_features``**: Limita o número de features que o algorítimo utiliza em cada divisão para determinar a melhor features de divisão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf67324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_dtree(trial):\n",
    "    \"\"\"Cria a instância de um modelo de árvore de decisão\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"max_depth\": trial.suggest_int(\"profundidade\", 2, 600, log=True),\n",
    "        \"criterion\": trial.suggest_categorical(\"critério\", ['entropy', 'log_loss', 'gini']),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_exemplos_split\", 2, 200, log=True),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_exemplos_folha\", 1, 100, log=True),\n",
    "        \"max_features\": trial.suggest_float(\"num_max_features\", 0, 1),\n",
    "        \"random_state\": SEED,\n",
    "    }\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_dtree = make_pipeline(\n",
    "            normalizador,\n",
    "            DecisionTreeClassifier(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_dtree = DecisionTreeClassifier(**parametros)\n",
    "\n",
    "    return modelo_dtree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce25b6",
   "metadata": {},
   "source": [
    "#### **Instância Floresta Aleatória (RF)**\n",
    "\n",
    "A floresta aleatória é uma técnica que combina o princípio de comitês com aleatorização adicional de features para criar múltiplas árvores de decisão diversas. Cada árvore na floresta é treinada em uma amostra bootstrap, amostragem aleatória com reposição, do conjunto de dados original e, em cada divisão da árvore, apenas um subconjunto aleatório de features é considerado para divisão. Essa aleatorização garante que as árvores individuais sejam diferentes umas das outras, reduzindo a correlação entre seus erros. Durante a predição, todas as árvores votam na classe final, com a maioria decidindo o resultado. Essa abordagem coletiva resulta em um modelo que geralmente supera árvores individuais, embora não seja interpretável e tenha um custo computacional maior.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``n_estimators``**: Número de árvores utilizadas no modelo\n",
    "\n",
    "- **``criterion``**: A função usada para medir a qualidade de um _split_ em cada nó\n",
    "\n",
    "- **``max_depth``**: Controla profundidade maxíma individual das árvores\n",
    "\n",
    "- **``min_samples_split``**: Número mínimo de amostras necessárias para dividir um nó\n",
    "\n",
    "- **``min_samples_leaf``**: Número mínimo de amostras em um nó folha\n",
    "\n",
    "- **``max_features``**: Limita o número de features que o algorítimo utiliza em cada divisão para determinar a melhor features de divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f968004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_rf(trial):\n",
    "    \"\"\"Cria a instância de um modelo de floresta aleatória.\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"n_estimators\": trial.suggest_int(\"num_arvores\", 2, 1000, log=True),\n",
    "        \"criterion\": trial.suggest_categorical(\"critério\", [\"log_loss\", \"gini\", \"entropy\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 600, log=True),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_exemplos_split\", 2, 200),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_exemplos_folha\", 1, 100),\n",
    "        \"max_features\": trial.suggest_float(\"num_max_atributos\", 0, 1),\n",
    "        \"n_jobs\": -1,\n",
    "        \"bootstrap\": True,\n",
    "        \"random_state\": SEED,\n",
    "    }\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "\n",
    "        modelo_rf = make_pipeline(\n",
    "            normalizador,\n",
    "            RandomForestClassifier(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_rf = RandomForestClassifier(**parametros)\n",
    "\n",
    "    return modelo_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0e84d",
   "metadata": {},
   "source": [
    "#### **Instância Regressão Logística (LR)**\n",
    "\n",
    "A regressão logística é um algoritmo de classificação que modela a probabilidade de uma amostra pertencer a uma classe específica usando a função logística (sigmoide). O modelo assume uma relação linear entre as features e o logarítimo da chance da probabilidade da classe positiva. A inclusão de termos de regularização (L1, L2 ou Elastic Net) ajuda a prevenir overfitting e a lidar com multicolinearidade entre as features.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``penalty``**: É o tipo de regularização utilizada \n",
    "\n",
    "- **``C``**: Controla a intesidade da regularização\n",
    "\n",
    "- **``l1_ratio ``**: Balanceamento entre penalidades L1 e L2, utilizada apenas pelo elasticnet\n",
    "\n",
    "Há também um parâmetro chamado `class_weight` que nos auxilia a lidar com variáveis ditas \"não-balanceadas\". Basicamente, esse hiperparâmetro decide se o modelo vai se importar mais com a acurácia no geral ou na identificação correta de _outliers_. Ele ajusta a influência de cada uma dos atributos durante o treinamento, forçando o modelo a prestar mais atenção nos valores menos frequentes em colunas de acordo com o peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de856cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_lr(trial):\n",
    "    \"\"\"Cria a instância de um modelo de Regressão Logística.\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"penalty\": trial.suggest_categorical(\"penalidade\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "        \"class_weight\": \"balanced\", \n",
    "        \"solver\": \"saga\",\n",
    "        \"max_iter\": 10000,\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": SEED,\n",
    "    }\n",
    "\n",
    "    if parametros[\"penalty\"] == \"elasticnet\":\n",
    "        parametros[\"l1_ratio\"] = trial.suggest_float(\"l1_ratio\", 0.1, 0.9)\n",
    "    \n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_lr = make_pipeline(\n",
    "            normalizador,\n",
    "            LogisticRegression(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_lr = LogisticRegression(**parametros)\n",
    "\n",
    "    return modelo_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ff230",
   "metadata": {},
   "source": [
    "#### **Instância Support Vector Classifier (SVC)**\n",
    "\n",
    "O SVC é um algoritimo que tem uma fundamentação matemática centrada em encontrar hiperplanos que maximizem as chamadas \"margens\" (distância entre o hiperplano de decisão e os exemplos mais próximos de cada classe) entre classes. Os hiperparâmetros controlam coisas como: o quão estrita a separação de pontos deve ser (hiperparâmetro c), que tipo de barreira de decisão usar (kernel) e o quão complexa essa barreira pode ser (gamma, degree). É vital otimizá-los para poder obter um modelo funcional que não superestime ou subestime a contribuição de uma variável.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``C``**: é um parâmetro regularizador, que controla a troca entre tamanho da margem e erro de classificação, um C pequeno tem melhor generalização, já um C maior tem um risco de _overfitting_.\n",
    "\n",
    "- **``kernel``**: controla o formato da fronteira de decisão.\n",
    "\n",
    "- **``gamma``**: é o coeficiente do kernel, que influencia o alcance de cada ponto individual no treinamento.\n",
    "\n",
    "- **``degree``**: é grau polinomial, caso o kernel seja polinomial, controla a complexidade do polinômio.\n",
    "\n",
    "- **``coef0``**: é o termo independente, que controla o deslocamento em kernels polinomiais ou sigmóides\n",
    "\n",
    "Além disso, há novamente o parâmetro `class_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a5c66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_svc(trial):\n",
    "    \"\"\"Cria a instância de um modelo de SVC\"\"\"\n",
    "    \n",
    "    parametros = {\n",
    "        \"C\": trial.suggest_float(\"C\", 0.01, 1000.0, log=True),\n",
    "        \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\",\"poly\", \"sigmoid\"]),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": SEED,\n",
    "        \"max_iter\": 600000,\n",
    "    }\n",
    "\n",
    "    if parametros[\"kernel\"] in [\"rbf\", \"poly\", \"sigmoid\"]:\n",
    "        entrada_gamma = trial.suggest_categorical(\"entrada_gamma\", [\"scale\", \"auto\", \"float\"])\n",
    "\n",
    "        if entrada_gamma == \"scale\":\n",
    "            parametros[\"gamma\"] = \"scale\"\n",
    "        elif entrada_gamma == \"auto\":\n",
    "            parametros[\"gamma\"] = \"auto\"\n",
    "        elif entrada_gamma == \"float\":\n",
    "            parametros[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-5, 1e2, log=True)\n",
    "    \n",
    "    if parametros[\"kernel\"] == \"poly\":\n",
    "        parametros[\"degree\"] = trial.suggest_int(\"degree\", 1, 4)\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_svc = make_pipeline(\n",
    "            normalizador,\n",
    "            SVC(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_svc = SVC(**parametros)\n",
    "\n",
    "    return modelo_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13b2a7",
   "metadata": {},
   "source": [
    "### **Função Objetivo**\n",
    "\n",
    "A seguir foi criada a função objetivo que é a função que irá computar a métrica de interesse. Neste caso, a métrica de interesse é a f1-macro, obtida por validação cruzada.\n",
    "\n",
    "A métrica ``f1-macro`` funciona da seguinte forma:\n",
    "\n",
    "- Precisão = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos) \n",
    "    - De todas as previsões positivas, quantas eram realmente positivas\n",
    "\n",
    "- Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos) \n",
    "    - De todos os casos realmente positivos, quantos foram identificados corretamente\n",
    "\n",
    "A métrica calcula a média harmônica entre a precisão e o recall:\n",
    "\n",
    "- **F1 = 2 × (Precision × Recall) / (Precision + Recall)**\n",
    "\n",
    "Nela, cada rótulo do target tem o mesmo peso, independente de quantos exemplos tenha, o que é útil para o nosso caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f64401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo(trial, X, y, num_folds, modelo=\"knn\"):\n",
    "    \"\"\"Função objetivo do optuna\"\"\"\n",
    "\n",
    "    if modelo == \"knn\":\n",
    "        modelo = cria_instancia_knn(trial)\n",
    "    elif modelo == \"dtree\":\n",
    "        modelo = cria_instancia_dtree(trial)\n",
    "    elif modelo == \"rf\":\n",
    "        modelo = cria_instancia_rf(trial)\n",
    "    elif modelo == \"lr\":\n",
    "        modelo = cria_instancia_lr(trial)\n",
    "    elif modelo == \"svc\":\n",
    "        modelo = cria_instancia_svc(trial)\n",
    "    \n",
    "    metricas = cross_val_score(\n",
    "        modelo, \n",
    "        X, \n",
    "        y, \n",
    "        scoring=\"f1_macro\",\n",
    "        cv=num_folds,\n",
    "        )\n",
    "    \n",
    "    return metricas.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e9059",
   "metadata": {},
   "source": [
    "### **Otimizando os Hiperparâmetros**\n",
    "\n",
    "A seguir foram criados os estudos (conjunto de trials) usando o ``create_study()``, cujo argumento ``direction='maximize'`` tem como objetivo maximizar a f1-macro. Foi o utilizado o ``storage`` para armazenar o progreso da busca e o  ``load_if_exists`` para que seja possível continuar a busca de onde ela parou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d78199b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:143\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:3301\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3280\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3281\u001b[0m \n\u001b[0;32m   3282\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3299\u001b[0m \n\u001b[0;32m   3300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:447\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1264\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:711\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 711\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\impl.py:175\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:388\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:673\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:899\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    900\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:895\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\create.py:661\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\default.py:629\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m NOME_DO_ESTUDO_RF \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrf_nanotoxiclogia_optuna\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m NOME_DO_ESTUDO_LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_nanotoxiclogia_optuna\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m objeto_de_estudo_knn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNOME_DO_ESTUDO_KNN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msqlite:///../resultados_optuna/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNOME_DO_ESTUDO_KNN\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_if_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m objeto_de_estudo_dtree \u001b[38;5;241m=\u001b[39m create_study(\n\u001b[0;32m     15\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mNOME_DO_ESTUDO_DTREE,\n\u001b[0;32m     17\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///../resultados_optuna/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNOME_DO_ESTUDO_DTREE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m objeto_de_estudo_svc \u001b[38;5;241m=\u001b[39m create_study(\n\u001b[0;32m     22\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mNOME_DO_ESTUDO_SVC,\n\u001b[0;32m     24\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///../resultados_optuna/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNOME_DO_ESTUDO_SVC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\_convert_positional_args.py:135\u001b[0m, in \u001b[0;36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m     )\n\u001b[0;32m    133\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(inferred_kwargs)\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\study.py:1297\u001b[0m, in \u001b[0;36mcreate_study\u001b[1;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`directions` must be a list of `minimize` or `maximize`, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirections\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor single-objective optimization, please use `direction` instead of `directions`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1291\u001b[0m     )\n\u001b[0;32m   1293\u001b[0m direction_objects \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1294\u001b[0m     d \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d, StudyDirection) \u001b[38;5;28;01melse\u001b[39;00m StudyDirection[d\u001b[38;5;241m.\u001b[39mupper()] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m directions\n\u001b[0;32m   1295\u001b[0m ]\n\u001b[1;32m-> 1297\u001b[0m storage \u001b[38;5;241m=\u001b[39m \u001b[43mstorages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1299\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mcreate_new_study(direction_objects, study_name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\storages\\__init__.py:49\u001b[0m, in \u001b[0;36mget_storage\u001b[1;34m(storage)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredis\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     47\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRedisStorage is removed at Optuna v3.1.0. Please use JournalRedisBackend instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m         )\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CachedStorage(\u001b[43mRDBStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(storage, RDBStorage):\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CachedStorage(storage)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\storages\\_rdb\\storage.py:238\u001b[0m, in \u001b[0;36mRDBStorage.__init__\u001b[1;34m(self, url, engine_kwargs, skip_compatibility_check, heartbeat_interval, grace_period, failed_trial_callback, skip_table_creation)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoped_session \u001b[38;5;241m=\u001b[39m sqlalchemy_orm\u001b[38;5;241m.\u001b[39mscoped_session(\n\u001b[0;32m    235\u001b[0m     sqlalchemy_orm\u001b[38;5;241m.\u001b[39msessionmaker(bind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_table_creation:\n\u001b[1;32m--> 238\u001b[0m     \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version_manager \u001b[38;5;241m=\u001b[39m _VersionManager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoped_session)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_compatibility_check:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\sql\\schema.py:5928\u001b[0m, in \u001b[0;36mMetaData.create_all\u001b[1;34m(self, bind, tables, checkfirst)\u001b[0m\n\u001b[0;32m   5904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_all\u001b[39m(\n\u001b[0;32m   5905\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5906\u001b[0m     bind: _CreateDropBind,\n\u001b[0;32m   5907\u001b[0m     tables: Optional[_typing_Sequence[Table]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5908\u001b[0m     checkfirst: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   5909\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5910\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create all tables stored in this metadata.\u001b[39;00m\n\u001b[0;32m   5911\u001b[0m \n\u001b[0;32m   5912\u001b[0m \u001b[38;5;124;03m    Conditional by default, will not attempt to recreate tables already\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5926\u001b[0m \n\u001b[0;32m   5927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5928\u001b[0m     \u001b[43mbind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_ddl_visitor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mddl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSchemaGenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtables\u001b[49m\n\u001b[0;32m   5930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:3251\u001b[0m, in \u001b[0;36mEngine._run_ddl_visitor\u001b[1;34m(self, visitorcallable, element, **kwargs)\u001b[0m\n\u001b[0;32m   3245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_ddl_visitor\u001b[39m(\n\u001b[0;32m   3246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3247\u001b[0m     visitorcallable: Type[InvokeDDLBase],\n\u001b[0;32m   3248\u001b[0m     element: SchemaVisitable,\n\u001b[0;32m   3249\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   3250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3251\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbegin() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m   3252\u001b[0m         conn\u001b[38;5;241m.\u001b[39m_run_ddl_visitor(visitorcallable, element, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:3241\u001b[0m, in \u001b[0;36mEngine.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3216\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Connection]:\n\u001b[0;32m   3218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a context manager delivering a :class:`_engine.Connection`\u001b[39;00m\n\u001b[0;32m   3219\u001b[0m \u001b[38;5;124;03m    with a :class:`.Transaction` established.\u001b[39;00m\n\u001b[0;32m   3220\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3239\u001b[0m \n\u001b[0;32m   3240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m-> 3241\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m   3242\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mbegin():\n\u001b[0;32m   3243\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m conn\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:3277\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[0;32m   3255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3256\u001b[0m \n\u001b[0;32m   3257\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3274\u001b[0m \n\u001b[0;32m   3275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 145\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:2440\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2439\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2442\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:143\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    145\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    146\u001b[0m             err, dialect, engine\n\u001b[0;32m    147\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\base.py:3301\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m   3280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3281\u001b[0m \n\u001b[0;32m   3282\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3299\u001b[0m \n\u001b[0;32m   3300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:447\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1264\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1267\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:711\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    709\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 711\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    714\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\impl.py:175\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:388\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:673\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:899\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    900\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\pool\\base.py:895\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\create.py:661\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sqlalchemy\\engine\\default.py:629\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "NOME_DO_ESTUDO_KNN = \"knn_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_DTREE = \"dtree_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_SVC = \"svc_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_RF = \"rf_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_LR = \"lr_nanotoxiclogia_optuna\"\n",
    "\n",
    "objeto_de_estudo_knn = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_KNN,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_KNN}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_dtree = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_DTREE,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_DTREE}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_svc = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_SVC,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_SVC}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_rf = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_RF,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_RF}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_lr = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_LR,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_LR}.db\",\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf20fa",
   "metadata": {},
   "source": [
    "Para realmente rodar o otimizador precisamos de uma função objetivo que tenha apenas um argumento, o `trial`. Para isso vamos definir a `funcao_objetivo_parcial`.\n",
    "\n",
    "Serão usados ``modelo='modelo'`` para cada modelo e um número de fols na validação cruzada igual a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27715019",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "\n",
    "def funcao_objetivo_parcial_knn(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"knn\")\n",
    "\n",
    "def funcao_objetivo_parcial_dtree(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"dtree\")\n",
    "\n",
    "def funcao_objetivo_parcial_rf(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"rf\")\n",
    "\n",
    "def funcao_objetivo_parcial_svc(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"svc\")\n",
    "\n",
    "def funcao_objetivo_parcial_lr(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"lr\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd3d69",
   "metadata": {},
   "source": [
    "Agora podemos definiro o número de novos trials e rodar cada otimização de modelo separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3622265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 19:10:00,834] Trial 1022 finished with value: 0.8402578592356329 and parameters: {'num_vizinhos': 1, 'pesos': 'uniform', 'tipo_distancia': 1, 'normalizar': True, 'tipo_norm': 'MaxAbs'}. Best is trial 148 with value: 0.8402578592356329.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_knn.optimize(funcao_objetivo_parcial_knn, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc79ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 19:10:01,648] Trial 1019 finished with value: 0.8788732598482317 and parameters: {'profundidade': 323, 'critério': 'entropy', 'min_exemplos_split': 2, 'min_exemplos_folha': 1, 'num_max_features': 0.4515889876495572, 'normalizar': False}. Best is trial 781 with value: 0.8961577595288454.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_dtree.optimize(funcao_objetivo_parcial_dtree, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a559b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 19:10:06,408] Trial 1420 finished with value: 0.8317574550969778 and parameters: {'C': 399.28811152097467, 'kernel': 'rbf', 'entrada_gamma': 'float', 'gamma': 2.7098565676297942e-05, 'normalizar': False}. Best is trial 1059 with value: 0.8508233453451532.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_svc.optimize(funcao_objetivo_parcial_svc, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 19:10:17,901] Trial 1426 finished with value: 0.8833010986926253 and parameters: {'num_arvores': 563, 'critério': 'entropy', 'max_depth': 596, 'min_exemplos_split': 11, 'min_exemplos_folha': 4, 'num_max_atributos': 0.5331878153463181, 'normalizar': False}. Best is trial 898 with value: 0.9112519576543396.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_rf.optimize(funcao_objetivo_parcial_rf, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f1fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 19:10:43,291] Trial 538 finished with value: 0.7374252859534545 and parameters: {'penalidade': 'l1', 'C': 295.7270238077543, 'normalizar': True, 'tipo_norm': 'MinMax'}. Best is trial 12 with value: 0.7383435156883571.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_lr.optimize(funcao_objetivo_parcial_lr, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fff7d",
   "metadata": {},
   "source": [
    "### **Vizualizando os Resultados**\n",
    "\n",
    "Agora podemos analizar o foi obtido com cada modelo e a partir disso definir qual deles teve o melhor estimativa de resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7355bb",
   "metadata": {},
   "source": [
    "#### **Resultado Dummy (baseline):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b97a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A estimativa do f1-macro para o Dummy foi: 0.868144690781797\n"
     ]
    }
   ],
   "source": [
    "print(f\"A estimativa do f1-macro para o Dummy foi: {f1_macro_estimativa_dummy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1697cd",
   "metadata": {},
   "source": [
    "#### **Resultado K-NN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4053b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial K-NN: 148\n",
      "Parâmetros do melhor trial : {'num_vizinhos': 1, 'pesos': 'uniform', 'tipo_distancia': 1, 'normalizar': True, 'tipo_norm': 'MaxAbs'}\n",
      "A melhor estimativa do f1-macro para o K-NN foi: 0.8402578592356329\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_knn = objeto_de_estudo_knn.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial K-NN: {melhor_trial_knn.number}\")\n",
    "print(f\"Parâmetros do melhor trial : {melhor_trial_knn.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para o K-NN foi: {objeto_de_estudo_knn.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079f295",
   "metadata": {},
   "source": [
    "#### **Resultado Árvore de Decisão:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18191687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial da Árvore de Decisão: 781\n",
      "Parâmetros do melhor trial da Árvore de Decisão: {'profundidade': 29, 'critério': 'entropy', 'min_exemplos_split': 2, 'min_exemplos_folha': 1, 'num_max_features': 0.4819347463126588, 'normalizar': True, 'tipo_norm': 'MinMax'}\n",
      "A melhor estimativa do f1-macro para a Árvore de Decisão foi: 0.8961577595288454\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_dtree = objeto_de_estudo_dtree.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial da Árvore de Decisão: {melhor_trial_dtree.number}\")\n",
    "print(f\"Parâmetros do melhor trial da Árvore de Decisão: {melhor_trial_dtree.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para a Árvore de Decisão foi: {objeto_de_estudo_dtree.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde835d8",
   "metadata": {},
   "source": [
    "#### **Resultado SVC:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial do SVC: 1059\n",
      "Parâmetros do melhor trial do SVC: {'C': 992.1950516156445, 'kernel': 'rbf', 'entrada_gamma': 'float', 'gamma': 3.25151263422672e-05, 'normalizar': False}\n",
      "A melhor estimativa do f1-macro para o SVC foi: 0.8508233453451532\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_svc = objeto_de_estudo_svc.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial do SVC: {melhor_trial_svc.number}\")\n",
    "print(f\"Parâmetros do melhor trial do SVC: {melhor_trial_svc.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para o SVC foi: {objeto_de_estudo_svc.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7deaa9c",
   "metadata": {},
   "source": [
    "#### **Resultado Floresta Aleatória:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58a0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial da Floresta Aleatória: 898\n",
      "Parâmetros do melhor trial da Floresta Aleatória: {'num_arvores': 403, 'critério': 'entropy', 'max_depth': 301, 'min_exemplos_split': 6, 'min_exemplos_folha': 1, 'num_max_atributos': 0.5282007906767744, 'normalizar': False}\n",
      "A melhor estimativa do f1-macro para a Floresta Aletória foi: 0.9112519576543396\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_rf = objeto_de_estudo_rf.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial da Floresta Aleatória: {melhor_trial_rf.number}\")\n",
    "print(f\"Parâmetros do melhor trial da Floresta Aleatória: {melhor_trial_rf.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para a Floresta Aletória foi: {objeto_de_estudo_rf.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73877f5a",
   "metadata": {},
   "source": [
    "#### **Resultado Regressão Logística:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial da Regressão Logística: 12\n",
      "Parâmetros do melhor trial da Regressão Logística: {'penalidade': 'l1', 'C': 137.97053160889004, 'normalizar': True, 'tipo_norm': 'MinMax'}\n",
      "A melhor estimativa do f1-macro para a Regressão Logística foi: 0.7383435156883571\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_lr = objeto_de_estudo_lr.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial da Regressão Logística: {melhor_trial_lr.number}\")\n",
    "print(f\"Parâmetros do melhor trial da Regressão Logística: {melhor_trial_lr.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para a Regressão Logística foi: {objeto_de_estudo_lr.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319dac1b",
   "metadata": {},
   "source": [
    "### **Conclusão a Otimização**\n",
    "\n",
    "Neste notebook, implementamos e otimizamos diversos modelos de aprendizado de máquina para prever a toxicidade de nanopartículas com base em suas características físico-químicas e condições experimentais. Utilizamos técnicas como agrupamento de dados para evitar vazamento, codificação one-hot para variáveis categóricas e validação cruzada para garantir a qualidade das métricas.\n",
    "\n",
    "Os modelos foram otimizados com o Optuna, que permitiu encontrar combinações de hiperparâmetros que maximizassem a estimativa do F1-score macro.\n",
    "\n",
    "| Modelo               |   F1-Macro |   Melhor Trial |\n",
    "|----------------------|------------|----------------|\n",
    "| Baseline             |     0.4339 |              - |\n",
    "| K-NN                 |     0.8402 |            148 |\n",
    "| Árvore de Decisão    |     0.8961 |            781 |\n",
    "| SVC                  |     0.8508 |           1059 |\n",
    "| Floresta Aleatória   |     0.9112 |            898 |\n",
    "| Regressão Logística  |     0.7383 |             12 |\n",
    "\n",
    "A principio foi possível observar que:\n",
    "\n",
    "Todos os modelos superaram significativamente o baseline, mostrando que as features utilizadas possuem um valor preditivo. Além disso, modelos como Floresta Aleatória e a Árvore de Decisão tiveram um melhor resultado.\n",
    "\n",
    "O avaliação desses modelos nos dados de teste pode ser vista no arquivo **``notebooks\\avaliacao_modelos.ipynb``**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f5504",
   "metadata": {},
   "source": [
    "### **Avaliando os modelos nos dados de treino**\n",
    "\n",
    "A validação cruzada fornece uma estimativa do desempenho; para medi-lo de fato, é necessário usar os dados de teste. Além do f-macro de cada modelo, será disposta a matriz de confusão para facilitar a visualização das previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53370db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_verdadeiro = y_teste\n",
    "\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ordem_labels = ['Nontoxic', 'Toxic']\n",
    "\n",
    "def matriz(y_previsto):\n",
    "    matriz_conf = confusion_matrix(y_verdadeiro, y_previsto, labels=ordem_labels)\n",
    "    df_conf = pd.DataFrame(matriz_conf, ordem_labels, ordem_labels)\n",
    "\n",
    "    print('Matriz de Confusão:')\n",
    "    display(heatmap(df_conf, annot=True, annot_kws={\"size\": 16}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04cc43",
   "metadata": {},
   "source": [
    "#### **Avaliando Baseline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6386e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868144690781797"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_baseline.fit(X_treino, y_treino)\n",
    "\n",
    "y_prev_baseline = modelo_baseline.predict(X_teste)\n",
    "f1_macro_baseline = f1_score(y_verdadeiro, y_prev_baseline, pos_label=\"Nontoxic\")\n",
    "\n",
    "print(f\"O f1_macro do modelo baseline foi: {f1_macro_baseline}\")\n",
    "matriz(y_prev_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156c13b",
   "metadata": {},
   "source": [
    "#### **Avaliando K-NN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O f1_macro do modelo K-NN foi: 0.9331602855288773\n"
     ]
    }
   ],
   "source": [
    "modelo_knn = cria_instancia_knn(melhor_trial_knn)\n",
    "modelo_knn.fit(X_treino, y_treino)\n",
    "\n",
    "y_prev_knn = modelo_knn.predict(X_teste)\n",
    "f1_macro_knn = f1_score(y_verdadeiro, y_prev_knn, pos_label=\"Nontoxic\")\n",
    "\n",
    "print(f\"O f1_macro do modelo K-NN foi: {f1_macro_knn}\")\n",
    "matriz(y_prev_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c5268",
   "metadata": {},
   "source": [
    "#### **Avaliando Árvore de Decisão:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O f1_macro do modelo foi: 0.9414929388029589\n"
     ]
    }
   ],
   "source": [
    "modelo_dtree = cria_instancia_dtree(melhor_trial_dtree)\n",
    "modelo_dtree.fit(X_treino, y_treino)\n",
    "\n",
    "y_prev_dtree = modelo_dtree.predict(X_teste)\n",
    "f1_macro_dtree = f1_score(y_verdadeiro, y_prev_dtree, pos_label=\"Nontoxic\")\n",
    "\n",
    "print(f\"O f1_macro do modelo de Árvore de Decisão foi: {f1_macro_dtree}\")\n",
    "matriz(y_prev_dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb828980",
   "metadata": {},
   "source": [
    "#### **Avaliando Floresta Aleatória:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f18320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O f1_macro do modelo foi: 0.9555997349237906\n"
     ]
    }
   ],
   "source": [
    "modelo_rf = cria_instancia_rf(melhor_trial_rf)\n",
    "modelo_rf.fit(X_treino, y_treino)\n",
    "\n",
    "y_prev_rf = modelo_rf.predict(X_teste)\n",
    "f1_macro_rf = f1_score(y_verdadeiro, y_prev_rf, pos_label=\"Nontoxic\")\n",
    "\n",
    "print(f\"O f1_macro do modelo de Floresta Aleatória foi: {f1_macro_rf}\")\n",
    "matriz(y_prev_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c13db",
   "metadata": {},
   "source": [
    "#### **Avaliando Regressão Logística:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dcb3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O f1_macro do modelo de Regressão Logística foi: 0.8544395924308588\n"
     ]
    }
   ],
   "source": [
    "modelo_lr = cria_instancia_lr(melhor_trial_lr)\n",
    "modelo_lr.fit(X_treino, y_treino)\n",
    "\n",
    "y_prev_lr = modelo_lr.predict(X_teste)\n",
    "f1_macro_lr = f1_score(y_verdadeiro, y_prev_lr, pos_label=\"Nontoxic\")\n",
    "\n",
    "print(f\"O f1_macro do modelo de Regressão Logística foi: {f1_macro_lr}\")\n",
    "matriz(y_prev_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d50cc",
   "metadata": {},
   "source": [
    "#### **Avaliando SVC:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80f0bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cria_instancia_svc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m modelo_svc \u001b[38;5;241m=\u001b[39m \u001b[43mcria_instancia_svc\u001b[49m(melhor_trial_svc)\n\u001b[0;32m      2\u001b[0m modelo_svc\u001b[38;5;241m.\u001b[39mfit(X_treino, y_treino)\n\u001b[0;32m      4\u001b[0m y_prev_svc \u001b[38;5;241m=\u001b[39m modelo_svc\u001b[38;5;241m.\u001b[39mpredict(X_teste)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cria_instancia_svc' is not defined"
     ]
    }
   ],
   "source": [
    "modelo_svc = cria_instancia_svc(melhor_trial_svc)\n",
    "modelo_svc.fit(X_treino, y_treino)\n",
    "\n",
    "y_prev_svc = modelo_svc.predict(X_teste)\n",
    "f1_macro_svc = f1_score(y_verdadeiro, y_prev_svc, pos_label=\"Nontoxic\")\n",
    "\n",
    "print(f\"O f1_macro do modelo SVC foi: {f1_macro_svc}\")\n",
    "matriz(y_prev_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b2fc9",
   "metadata": {},
   "source": [
    "#### **Métricas alternativas**\n",
    "\n",
    "Não só o f1-macro pode ser usado como métrica de desempenho. Para classificação binária, podem ser feitos cálculos como **acurácia** e **recall score**. Ambas são crescentes com o desempenho do modelo (ou seja, sempre que optar por elas, seu objetivo será *maximizá-las*) e variam de 0 a 1, mas são diferentes.\n",
    "\n",
    "**Acurácia** é a razão entre a soma dos verdadeiros positivos e dos verdadeiros negativos e o número total de dados. Ou seja, é a *frequência com que a previsão coincide com a realidade*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00486640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuracia(y_previsto):\n",
    "    return accuracy_score(y_verdadeiro, y_previsto)\n",
    "\n",
    "acuracia_baseline = acuracia(y_prev_baseline)\n",
    "acuracia_knn = acuracia(y_prev_knn)\n",
    "acuracia_dtree = acuracia(y_prev_dtree)\n",
    "acuracia_rf = acuracia(y_prev_rf)\n",
    "acuracia_lr = acuracia(y_prev_lr)\n",
    "acuracia_svc = acuracia(y_prev_svc)\n",
    "\n",
    "print(f\"A acurácia do modelo baseline foi: {acuracia_baseline}\")\n",
    "print(f\"A acurácia do modelo knn foi: {acuracia_knn}\")\n",
    "print(f\"A acurácia do modelo de árvore de decisão foi: {acuracia_dtree}\")\n",
    "print(f\"A acurácia do modelo de floresta aleatória foi: {acuracia_rf}\")\n",
    "print(f\"A acurácia do modelo de regressão logística foi: {acuracia_lr}\")\n",
    "print(f\"A acurácia do modelo SVC foi: {acuracia_svc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f164dee",
   "metadata": {},
   "source": [
    "Já **recall** é a razão entre o número de verdadeiros positivos e a soma dos verdadeiros positivos com os falsos negativos. Ou seja, é a *razão entre os positivos corretamente previstos e todos os dados que são positivos na realidade*. Dessa forma, é uma boa métrica em casos em que é muito importante identificar os positivos (por exemplo, compostos tóxicos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15213912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_previsto):\n",
    "    return recall_score(y_verdadeiro, y_previsto, labels=ordem_labels)\n",
    "\n",
    "recall_baseline = recall(y_prev_baseline)\n",
    "recall_knn = recall(y_prev_knn)\n",
    "recall_dtree = recall(y_prev_dtree)\n",
    "recall_rf = recall(y_prev_rf)\n",
    "recall_lr = recall(y_prev_lr)\n",
    "recall_svc = recall(y_prev_svc)\n",
    "\n",
    "print(f\"O recall score do modelo baseline foi: {recall_baseline}\")\n",
    "print(f\"O recall score do modelo knn foi: {recall_knn}\")\n",
    "print(f\"O recall score do modelo de árvore de decisão foi: {recall_dtree}\")\n",
    "print(f\"O recall score do modelo de floresta aleatória foi: {recall_rf}\")\n",
    "print(f\"O recall score do modelo de regressão logística foi: {recall_lr}\")\n",
    "print(f\"O recall score do modelo SVC foi: {recall_svc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a27535",
   "metadata": {},
   "source": [
    "Repare que o recall do baseline é máximo, igual a 1. Isso ocorre sempre que o valor positivo é a moda dos dados de treino, porque o número de negativos previstos (falsos ou verdadeiros) é zero! O que não quer dizer que o baseline é o melhor modelo: se os negativos fossem a moda, o número de positivos previstos seria zero, e o recall também. Por isso, a escolha da métrica deve ser adequada ao modelo e ao conjunto de dados - lembre que ela é importante para a otimização de hiperparâmetros, na qual usou-se apenas o f1-macro.\n",
    "\n",
    "Observe a comparação entre os desempenhos estimados por validação cruzada e medidos com diferentes métricas:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
