{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44ea453",
   "metadata": {},
   "source": [
    "## **Notebook com os Modelos finais**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3f282",
   "metadata": {},
   "source": [
    "**Autores:**\n",
    "\n",
    "- Arthur Brandão do Nascimento\n",
    "\n",
    "- Caio Ávila Paulo\n",
    "\n",
    "- Matheus Macedo do Nascimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f14d48",
   "metadata": {},
   "source": [
    "## **Introdução**\n",
    "Este notebook tem por objetivo implementar e comparar diferentes algoritmos de aprendizado de máquina supervisionado de classificação. A partir de características como composição, tamanho e tempo de exposição de diferentes materiais, será prevista sua toxicidade.\n",
    "\n",
    "Os algoritmos utilizados serão os de k vizinhos mais próximos (knn), árvore de decisão, floresta aleatória, Support Vector Classifier (SVC) e Regressão Logística. O desempenho de cada um deles será estimado por validação cruzada do tipo k-fold e os hiperparâmetros dos modelos serão otimizados com o ``optuna``. Além disso, um modelo baseline será estabelecido para fins de comparação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c83cb8",
   "metadata": {},
   "source": [
    "### **Importando as bibliotecas necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae229090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from optuna import create_study\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8224d56",
   "metadata": {},
   "source": [
    "### **Importando o dataset**\n",
    "\n",
    "O dataset escolhido tem, a princípio 3923 linhas e 17 colunas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e91207d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3923, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material_type</th>\n",
       "      <th>Core_size</th>\n",
       "      <th>Hydro_size</th>\n",
       "      <th>Surface_charge</th>\n",
       "      <th>Surface_area</th>\n",
       "      <th>Formation_enthalpy</th>\n",
       "      <th>Conduction_band</th>\n",
       "      <th>Valence_band</th>\n",
       "      <th>Electronegativity</th>\n",
       "      <th>Assay</th>\n",
       "      <th>Cell_name</th>\n",
       "      <th>Cell_species</th>\n",
       "      <th>Cell_origin</th>\n",
       "      <th>Cell_type</th>\n",
       "      <th>Exposure_time</th>\n",
       "      <th>Exposure_dose</th>\n",
       "      <th>Toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>-17.345</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.67</td>\n",
       "      <td>MTT</td>\n",
       "      <td>HCMEC</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Normal</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Nontoxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Material_type  Core_size  Hydro_size  Surface_charge  Surface_area  \\\n",
       "0         Al2O3       39.7       267.0            36.3          64.7   \n",
       "1         Al2O3       39.7       267.0            36.3          64.7   \n",
       "2         Al2O3       39.7       267.0            36.3          64.7   \n",
       "3         Al2O3       39.7       267.0            36.3          64.7   \n",
       "4         Al2O3       39.7       267.0            36.3          64.7   \n",
       "\n",
       "   Formation_enthalpy  Conduction_band  Valence_band  Electronegativity Assay  \\\n",
       "0             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "1             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "2             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "3             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "4             -17.345            -1.51         -9.81               5.67   MTT   \n",
       "\n",
       "  Cell_name Cell_species Cell_origin Cell_type  Exposure_time  Exposure_dose  \\\n",
       "0     HCMEC        Human       Blood    Normal           24.0          0.001   \n",
       "1     HCMEC        Human       Blood    Normal           24.0          0.010   \n",
       "2     HCMEC        Human       Blood    Normal           24.0          0.100   \n",
       "3     HCMEC        Human       Blood    Normal           24.0          1.000   \n",
       "4     HCMEC        Human       Blood    Normal           24.0          5.000   \n",
       "\n",
       "   Toxicity  \n",
       "0  Nontoxic  \n",
       "1  Nontoxic  \n",
       "2  Nontoxic  \n",
       "3  Nontoxic  \n",
       "4  Nontoxic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/dataset_nanotoxicologia_combinado.csv\")\n",
    "\n",
    "display(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b2540",
   "metadata": {},
   "source": [
    "### **Definindo as ``FEATURES`` e o ``TARGET``**\n",
    "\n",
    "As features serão separadas entre aquelas que já são valores numéricos (``FEATURES_NUM``) e aquelas que serão convertidas em valores binários (``FEATURES_DUMMY``).\n",
    "\n",
    "Variável alvo (**``TARGET``**):\n",
    "- ``\"Toxicity\"`` - \n",
    "\n",
    "Features Numéricas (**``FEATURES_NUM``**):\n",
    "\n",
    "[Adicionar o que é cada uma das colunas do dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55751354",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_NUM = [\"Core_size\", \n",
    "                \"Hydro_size\", \n",
    "                \"Surface_charge\", \n",
    "                \"Surface_area\", \n",
    "                \"Formation_enthalpy\", \n",
    "                \"Conduction_band\", \n",
    "                \"Valence_band\", \n",
    "                \"Electronegativity\", \n",
    "                \"Exposure_time\", \n",
    "                \"Exposure_dose\"\n",
    "]\n",
    "\n",
    "FEATURES_DUMMY = [\"Material_type\", \"Assay\", \"Cell_name\", \"Cell_species\", \"Cell_origin\", \"Cell_type\"]\n",
    "\n",
    "TARGET = [\"Toxicity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a1da49",
   "metadata": {},
   "source": [
    "### **Evitando vazamento de dados pelo ``groupby()``**\n",
    "Pode ser que vários dados do dataset sejam iguais em todos os atributos, diferindo (ou não) apenas no target. Dessa forma, alguns desses dados poderiam acabar sendo usado na etapa de treino e outros na fase de teste. Isso faria com que a métrica não refletisse o real desempenho do modelo; afinal, ele já \"conheceria\" alguns dados de teste, o que acarreta uma previsão enviesada.\n",
    "\n",
    "Para evitar esse tipo de vazamento, *antes* do split de treino e teste, é necessário acabar com essa redundância. Isso é feito agrupando todos os dados duplicados em um só: os atributos continuam os mesmos, mas apenas um valor de target é utilizado, a partir de uma estatística dos dados originais. Como o target é categórico, será usada a moda.\n",
    "\n",
    "Importante que os dados duplicados não precisam ser cópias idênticas: se todos os atributos forem muito próximos (apesar de não serem iguais), o vazamento de dados ocorrerá da mesma maneira. Por isso, antes de identificar dados repetidos e agrupá-los, arredonda-se o valor de cada atributo em uma casa adequada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13d84b",
   "metadata": {},
   "source": [
    "#### **Arredondando**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b5afe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3923, 17)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casa_arredondamento = {\n",
    "    \"Core_size\": 0, \n",
    "    \"Hydro_size\": 0, \n",
    "    \"Surface_charge\": 0, \n",
    "    \"Surface_area\": 0, \n",
    "    \"Formation_enthalpy\": 0, \n",
    "    \"Conduction_band\": 0,\n",
    "    \"Valence_band\": 0, \n",
    "    \"Electronegativity\": 0, \n",
    "    \"Exposure_time\": 1, \n",
    "    \"Exposure_dose\": 1,\n",
    "}\n",
    "\n",
    "df_round = df.round(casa_arredondamento)\n",
    "\n",
    "df_round.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7a234",
   "metadata": {},
   "source": [
    "Como nós podemos ver pelo código abaixo esse dataset possui alguns dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb964f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas em df_round: 43\n"
     ]
    }
   ],
   "source": [
    "num_duplicados = df_round[FEATURES_NUM + FEATURES_DUMMY].duplicated().sum()\n",
    "print(f\"Número de linhas duplicadas em df_round: {num_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56d2ef",
   "metadata": {},
   "source": [
    "#### **Agrupando**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce360a28",
   "metadata": {},
   "source": [
    "O [``agg()``](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) é um método do pandas usado para aplicar uma ou mais operações de agregação em grupos de dados. Como o target (``\"Toxicity\"``) é categórico, usaremos a moda para decidir o rótulo daquele grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5173552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def calcular_moda(serie):\n",
    "    \"\"\"Calcula a moda de uma série, retornando o primeiro valor se não houver moda clara\"\"\"\n",
    "    moda = stats.mode(serie)\n",
    "    return moda[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6124a761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O shape (linhas x colunas) do df_round é: (3923, 17)\n",
      "O shape (linhas x colunas) do df_tratado é: (3880, 17)\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df_round.groupby(FEATURES_NUM + FEATURES_DUMMY, sort=False)\n",
    "\n",
    "def calcular_moda(serie):\n",
    "    \"\"\"Calcula a moda de uma série\"\"\"\n",
    "    moda = serie.mode()\n",
    "    return moda[0]\n",
    "\n",
    "agg_dict = {\n",
    "    **{col: \"mean\" for col in FEATURES_NUM},\n",
    "    **{col: calcular_moda for col in FEATURES_DUMMY},\n",
    "    \"Toxicity\": calcular_moda\n",
    "}\n",
    "\n",
    "df_grouped = df_grouped.agg(agg_dict)\n",
    "df_grouped = df_grouped.reset_index(drop=True)\n",
    "\n",
    "print(f\"O shape (linhas x colunas) do df_round é: {df_round.shape}\")\n",
    "print(f\"O shape (linhas x colunas) do df_tratado é: {df_grouped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b70b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas em df_grouped: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicados = df_grouped[FEATURES_NUM + FEATURES_DUMMY].duplicated().sum()\n",
    "print(f\"Número de linhas duplicadas em df_grouped: {num_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0d7ef",
   "metadata": {},
   "source": [
    "Como podemos ver não há mais valores duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d8933",
   "metadata": {},
   "source": [
    "### **Fazendo a codificação One-Hot**\n",
    "Os algoritmos de aprendizado de máquina utilizados exigem que todos os atributos sejam numéricos. Dessa forma, é necessário transformar os dados qualitativos adequadamente.  O codificador One-Hot transforma uma coluna de dados categóricos em várias colunas, cada qual representando um dos rótulos possíveis; se o dado originalmente tinha aquele rótulo, atribui-se o valor 1, caso contrário preenche-se com 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b40473a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3880, 203)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Core_size</th>\n",
       "      <th>Hydro_size</th>\n",
       "      <th>Surface_charge</th>\n",
       "      <th>Surface_area</th>\n",
       "      <th>Formation_enthalpy</th>\n",
       "      <th>Conduction_band</th>\n",
       "      <th>Valence_band</th>\n",
       "      <th>Electronegativity</th>\n",
       "      <th>Exposure_time</th>\n",
       "      <th>Exposure_dose</th>\n",
       "      <th>...</th>\n",
       "      <th>Cell_origin_Pancreas</th>\n",
       "      <th>Cell_origin_Plant cell</th>\n",
       "      <th>Cell_origin_Prostate</th>\n",
       "      <th>Cell_origin_Skin</th>\n",
       "      <th>Cell_origin_Stomach</th>\n",
       "      <th>Cell_origin_Tetis</th>\n",
       "      <th>Cell_origin_Tongue</th>\n",
       "      <th>Cell_origin_Umbilical vein</th>\n",
       "      <th>Cell_type_Cancer</th>\n",
       "      <th>Cell_type_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Core_size  Hydro_size  Surface_charge  Surface_area  Formation_enthalpy  \\\n",
       "0       40.0       267.0            36.0          65.0               -17.0   \n",
       "1       40.0       267.0            36.0          65.0               -17.0   \n",
       "2       40.0       267.0            36.0          65.0               -17.0   \n",
       "3       40.0       267.0            36.0          65.0               -17.0   \n",
       "4       40.0       267.0            36.0          65.0               -17.0   \n",
       "\n",
       "   Conduction_band  Valence_band  Electronegativity  Exposure_time  \\\n",
       "0             -2.0         -10.0                6.0           24.0   \n",
       "1             -2.0         -10.0                6.0           24.0   \n",
       "2             -2.0         -10.0                6.0           24.0   \n",
       "3             -2.0         -10.0                6.0           24.0   \n",
       "4             -2.0         -10.0                6.0           24.0   \n",
       "\n",
       "   Exposure_dose  ... Cell_origin_Pancreas  Cell_origin_Plant cell  \\\n",
       "0            0.0  ...                    0                       0   \n",
       "1            0.1  ...                    0                       0   \n",
       "2            1.0  ...                    0                       0   \n",
       "3            5.0  ...                    0                       0   \n",
       "4           10.0  ...                    0                       0   \n",
       "\n",
       "   Cell_origin_Prostate  Cell_origin_Skin  Cell_origin_Stomach  \\\n",
       "0                     0                 0                    0   \n",
       "1                     0                 0                    0   \n",
       "2                     0                 0                    0   \n",
       "3                     0                 0                    0   \n",
       "4                     0                 0                    0   \n",
       "\n",
       "   Cell_origin_Tetis  Cell_origin_Tongue  Cell_origin_Umbilical vein  \\\n",
       "0                  0                   0                           0   \n",
       "1                  0                   0                           0   \n",
       "2                  0                   0                           0   \n",
       "3                  0                   0                           0   \n",
       "4                  0                   0                           0   \n",
       "\n",
       "   Cell_type_Cancer  Cell_type_Normal  \n",
       "0                 0                 1  \n",
       "1                 0                 1  \n",
       "2                 0                 1  \n",
       "3                 0                 1  \n",
       "4                 0                 1  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, dtype=np.int32)\n",
    "dummy_encoded = encoder.fit_transform(df_grouped[FEATURES_DUMMY])\n",
    "\n",
    "dummy_columns = encoder.get_feature_names_out(FEATURES_DUMMY)\n",
    "df_dummy = pd.DataFrame(dummy_encoded, columns=dummy_columns, index=df_grouped.index)\n",
    "\n",
    "df_dummy = pd.concat([df_grouped[FEATURES_NUM + TARGET], df_dummy], axis=1)\n",
    "FEATURES_FINAL = FEATURES_NUM + list(dummy_columns)\n",
    "\n",
    "display(df_dummy.shape)\n",
    "display(df_dummy.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9e2c1",
   "metadata": {},
   "source": [
    "### **Definindo os dados de treino e de teste**\n",
    "Com o dataframe devidamente tratado, pode ser feita a divisão dos dados em teste e treino. No caso será utilizado o ``stratify`` pois há um certo desbalanço no dataset, havendo mais dados sobre nanopartículas não tóxicas do que nanopartículas tóxicas, o ``\"stratify\"`` mantém a proporção das classes em ambos os conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d1b08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TESTE = 0.25\n",
    "SEED = 404\n",
    "\n",
    "valores_target = df_dummy[TARGET].values.ravel()\n",
    "\n",
    "df_treino, df_teste = train_test_split(df_dummy, test_size=TAMANHO_TESTE, random_state=SEED, stratify=valores_target)\n",
    "\n",
    "X_teste = df_teste.reindex(FEATURES_FINAL, axis=1)\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "X_treino = df_treino.reindex(FEATURES_FINAL, axis=1)\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d5eb3",
   "metadata": {},
   "source": [
    "### **Criando os modelos e espaços de busca**\n",
    "\n",
    "Serão criados os seguintes modelos para comparação:\n",
    "\n",
    "- Baseline (DummyClassifier)\n",
    "- k-Nearest Neighbors classifier (KNN)\n",
    "- Árvore de Decisão\n",
    "- Floresta Aleatória\n",
    "- Regressão Logística\n",
    "- Support Vector Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c32d8",
   "metadata": {},
   "source": [
    "#### **Baseline**\n",
    "\n",
    "O baseline estabelece uma referência mínima de desempenho, onde qualquer modelo útil deve superar essa referência.\n",
    "\n",
    "No caso, foi utilizado o ``DummyClassifier(strategy='most_frequent')``, que prevê sempre a moda dos valores de y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab0e5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "f1_macro_estimativa_dummy = cross_val_score(modelo_baseline, X_treino, y_treino, scoring=\"f1_macro\", cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7684c60",
   "metadata": {},
   "source": [
    "#### **Implementação dos Modelos com o Optuna**\n",
    "O Optuna é um framework de otimização de hiperparâmetros. Ele automatiza o processo de enontrar o conjunto ótimo de hiperparâmetros para um dado modelo, almeando minimizar ou maximizar uma função objetiva específica.\n",
    "\n",
    "No Optuna, os ``Trials`` são as tentativas com diferentes combinações de hiperparâmetros e o ``Study`` é o conjunto de trials para um determinado objetivo.\n",
    "\n",
    "Nesse contexto, a função ``cria_instancia_modelo`` serve para criar uma instância do modelo escolhido, recebendo um trial.\n",
    "Para definir o espaço do dicionário dos parâmetros é usado o ``trial.suggest_*()``.\n",
    "\n",
    "Além disso, foi utilizada a decisão de normalização dos dados como um hiperparâmetro adicional. Para isso foi criado um curto **pipeline** com o ``make_pipeline()``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112195a",
   "metadata": {},
   "source": [
    "#### **Instância K-NN**\n",
    "\n",
    "Baseado no princípio de que exemplos similares tendem a pertencer à mesma classe. Para classificar uma nova amostra, o algoritmo calcula as distâncias entre essa amostra e os pontos do conjunto de treinamento, identifica os K vizinhos mais próximos e realiza uma votação majoritária entre suas classes.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``n_neighbors``**: número de vizinhos\n",
    "\n",
    "- **``weights``**: uniform, sem pesos, ou distance, em que vizinhos mais próximos tem mais peso\n",
    "\n",
    "- **``p``**: tipo de distância, 1=Manhattan, 2=Euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb30db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_knn(trial):\n",
    "    \"\"\"Cria uma instância de um modelo KNN.\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"n_neighbors\": trial.suggest_int(\"num_vizinhos\", 1, 200, log=True),\n",
    "        \"weights\": trial.suggest_categorical(\"pesos\", [\"uniform\", \"distance\"]),\n",
    "        \"p\": trial.suggest_int(\"tipo_distancia\", 1, 2),\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_knn = make_pipeline(\n",
    "            normalizador,\n",
    "            KNeighborsClassifier(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_knn = KNeighborsClassifier(**parametros)\n",
    "\n",
    "    return modelo_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8830c",
   "metadata": {},
   "source": [
    "#### **Instância Árvore de Decisão**\n",
    "\n",
    "O algoritmo da árvore de decisão constrói uma estrutura similar a um fluxograma, onde cada nó interno representa uma decisão baseada em uma feature específica, cada ramo representa o resultado dessa decisão e cada nó folha representa a classe predita. O processo de construção da árvore segue uma estratégia visa a máxima separação dos nós resultantes em cada divisão, utilizando critérios como entropia ou índice Gini para medir a homogeneidade das classes. A principal vantagem das árvores de decisão reside em sua alta interpretabilidade.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``max_depth``**: Profundidade máxima da árvore\n",
    "\n",
    "- **``criterion``**: A função usada para medir a qualidade de um _split_ em cada nó\n",
    "\n",
    "- **``min_samples_split``**: Número mínimo de amostras necessárias para dividir um nó\n",
    "\n",
    "- **``min_samples_leaf``**:  Número mínimo de amostras em um nó folha\n",
    "\n",
    "- **``max_features``**: Limita o número de features que o algorítimo utiliza em cada divisão para determinar a melhor features de divisão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf67324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_dtree(trial):\n",
    "    \"\"\"Cria a instância de um modelo de árvore de decisão\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"max_depth\": trial.suggest_int(\"profundidade\", 2, 600, log=True),\n",
    "        \"criterion\": trial.suggest_categorical(\"critério\", ['entropy', 'log_loss', 'gini']),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_exemplos_split\", 2, 200, log=True),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_exemplos_folha\", 1, 100, log=True),\n",
    "        \"max_features\": trial.suggest_float(\"num_max_features\", 0, 1),\n",
    "        \"random_state\": SEED,\n",
    "    }\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_dtree = make_pipeline(\n",
    "            normalizador,\n",
    "            DecisionTreeClassifier(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_dtree = DecisionTreeClassifier(**parametros)\n",
    "\n",
    "    return modelo_dtree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce25b6",
   "metadata": {},
   "source": [
    "#### **Instância Floresta Aleatória (RF)**\n",
    "\n",
    "A floresta aleatória é uma técnica que combina o princípio de comitês com aleatorização adicional de features para criar múltiplas árvores de decisão diversas. Cada árvore na floresta é treinada em uma amostra bootstrap, amostragem aleatória com reposição, do conjunto de dados original e, em cada divisão da árvore, apenas um subconjunto aleatório de features é considerado para divisão. Essa aleatorização garante que as árvores individuais sejam diferentes umas das outras, reduzindo a correlação entre seus erros. Durante a predição, todas as árvores votam na classe final, com a maioria decidindo o resultado. Essa abordagem coletiva resulta em um modelo que geralmente supera árvores individuais, embora possua uma interpretabilidade muito inferior.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``n_estimators``**: Número de árvores utilizadas no modelo\n",
    "\n",
    "- **``criterion``**: A função usada para medir a qualidade de um _split_ em cada nó\n",
    "\n",
    "- **``max_depth``**: Controla profundidade maxíma individual das árvores\n",
    "\n",
    "- **``min_samples_split``**: Número mínimo de amostras necessárias para dividir um nó\n",
    "\n",
    "- **``min_samples_leaf``**: Número mínimo de amostras em um nó folha\n",
    "\n",
    "- **``max_features``**: Limita o número de features que o algorítimo utiliza em cada divisão para determinar a melhor features de divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f968004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_rf(trial):\n",
    "    \"\"\"Cria a instância de um modelo de floresta aleatória.\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"n_estimators\": trial.suggest_int(\"num_arvores\", 2, 1000, log=True),\n",
    "        \"criterion\": trial.suggest_categorical(\"critério\", [\"log_loss\", \"gini\", \"entropy\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 600, log=True),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_exemplos_split\", 2, 200),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_exemplos_folha\", 1, 100),\n",
    "        \"max_features\": trial.suggest_float(\"num_max_atributos\", 0, 1),\n",
    "        \"n_jobs\": -1,\n",
    "        \"bootstrap\": True,\n",
    "        \"random_state\": SEED,\n",
    "    }\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "\n",
    "        modelo_rf = make_pipeline(\n",
    "            normalizador,\n",
    "            RandomForestClassifier(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_rf = RandomForestClassifier(**parametros)\n",
    "\n",
    "    return modelo_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0e84d",
   "metadata": {},
   "source": [
    "#### **Instância Regressão Logística (LR)**\n",
    "\n",
    "A regressão logística é um algoritmo de classificação que modela a probabilidade de uma amostra pertencer a uma classe específica usando a função logística (sigmoide). O modelo assume uma relação linear entre as features e o logarítimo da chance da probabilidade da classe positiva. A inclusão de termos de regularização (L1, L2 ou Elastic Net) ajuda a prevenir overfitting e a lidar com multicolinearidade entre as features.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``penalty``**: É o tipo de regularização utilizada \n",
    "\n",
    "- **``C``**: Controla a intesidade da regularização\n",
    "\n",
    "- **``l1_ratio ``**: Balanceamento entre penalidades L1 e L2, utilizada apenas pelo elasticnet\n",
    "\n",
    "Há também um parâmetro chamado `class_weight` que nos auxilia a lidar com variáveis ditas \"não-balanceadas\", basicamente esse hiperparâmetro decide se o modelo vai se importar mais com a acurácia no geral ou na identificação correta de _outliers_. Ele ajusta a influência de cada uma das clsses durante o treinamento, forçando o modelo a prestar mais atenção nas classes minoritárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de856cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_lr(trial):\n",
    "    \"\"\"Cria a instância de um modelo de Regressão Logística.\"\"\"\n",
    "\n",
    "    parametros = {\n",
    "        \"penalty\": trial.suggest_categorical(\"penalidade\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "        \"class_weight\": \"balanced\", \n",
    "        \"solver\": \"saga\",\n",
    "        \"max_iter\": 10000,\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": SEED,\n",
    "    }\n",
    "\n",
    "    if parametros[\"penalty\"] == \"elasticnet\":\n",
    "        parametros[\"l1_ratio\"] = trial.suggest_float(\"l1_ratio\", 0.1, 0.9)\n",
    "    \n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_lr = make_pipeline(\n",
    "            normalizador,\n",
    "            LogisticRegression(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_lr = LogisticRegression(**parametros)\n",
    "\n",
    "    return modelo_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ff230",
   "metadata": {},
   "source": [
    "#### **Instância Support Vector Classifier (SVC)**\n",
    "\n",
    "O SVC é um algoritimo que tem uma fundamentação matemática centrada em encontrar hiperplanos que maximizem as chamadas \"margens\" (distância entre o hiperplano de decisão e os exemplos mais próximos de cada classe) entre classes. Os hiperparâmetros controlam coisas como: o quão estrita a separação de pontos deve ser (hiperparâmetro c), que tipo de barreira de decisão usar (kernel) e o quão complexa essa barreira pode ser (gamma, degree). É vital otimizá-los para poder obter um modelo funcional que não superestime ou subestime a contribuição de uma variável.\n",
    "\n",
    "Hiperparâmetros Otimizados:\n",
    "\n",
    "- **``C``**: é um parâmetro regularizador, que controla a troca entre tamanho da margem e erro de classificação, um C pequeno tem melhor generalização, já um C maior tem um risco de _overfitting_.\n",
    "\n",
    "- **``kernel``**: controla o formato da fronteira de decisão.\n",
    "\n",
    "- **``gamma``**: é o coeficiente do kernel, que influencia o alcance de cada ponto individual no treinamento.\n",
    "\n",
    "- **``degree``**: é grau polinomial, caso o kernel seja polinomial, controla a complexidade do polinômio.\n",
    "\n",
    "- **``coef0``**: é o termo independente, que controla o deslocamento em kernels polinomiais ou sigmóides\n",
    "\n",
    "Há também um parâmetro chamado `class_weight` que nos auxilia a lidar com variáveis ditas \"não-balanceadas\", basicamente esse hiperparâmetro decide se o modelo vai se importar mais com a acurácia no geral ou na identificação correta de _outliers_. Ele ajusta a influência de cada uma das clsses durante o treinamento, forçando o modelo a prestar mais atenção nas classes minoritárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a5c66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_instancia_svc(trial):\n",
    "    \"\"\"Cria a instância de um modelo de SVC\"\"\"\n",
    "    \n",
    "    parametros = {\n",
    "        \"C\": trial.suggest_float(\"C\", 0.01, 1000.0, log=True),\n",
    "        \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\",\"poly\", \"sigmoid\"]),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": SEED,\n",
    "        \"max_iter\": 600000,\n",
    "    }\n",
    "\n",
    "    if parametros[\"kernel\"] in [\"rbf\", \"poly\", \"sigmoid\"]:\n",
    "        entrada_gamma = trial.suggest_categorical(\"entrada_gamma\", [\"scale\", \"auto\", \"float\"])\n",
    "\n",
    "        if entrada_gamma == \"scale\":\n",
    "            parametros[\"gamma\"] = \"scale\"\n",
    "        elif entrada_gamma == \"auto\":\n",
    "            parametros[\"gamma\"] = \"auto\"\n",
    "        elif entrada_gamma == \"float\":\n",
    "            parametros[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-5, 1e2, log=True)\n",
    "    \n",
    "    if parametros[\"kernel\"] == \"poly\":\n",
    "        parametros[\"degree\"] = trial.suggest_int(\"degree\", 1, 4)\n",
    "\n",
    "    normalizar = trial.suggest_categorical(\"normalizar\", [True, False])\n",
    "\n",
    "    if normalizar:\n",
    "        tipo_normalizacao = trial.suggest_categorical(\"tipo_norm\", [\"Standard\", \"MinMax\", \"MaxAbs\"])\n",
    "\n",
    "        if tipo_normalizacao == \"Standard\":\n",
    "            normalizador = StandardScaler()\n",
    "        elif tipo_normalizacao == \"MinMax\":\n",
    "            normalizador = MinMaxScaler()\n",
    "        elif tipo_normalizacao == \"MaxAbs\":\n",
    "            normalizador = MaxAbsScaler()\n",
    "            \n",
    "        modelo_svc = make_pipeline(\n",
    "            normalizador,\n",
    "            SVC(**parametros)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        modelo_svc = SVC(**parametros)\n",
    "\n",
    "    return modelo_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13b2a7",
   "metadata": {},
   "source": [
    "### **Função Objetivo**\n",
    "\n",
    "A seguir foi criada a função objetivo que é a função que irá computar a métrica de interesse. Neste caso, a métrica de interesse é a f1-macro, obtida por validação cruzada.\n",
    "\n",
    "A métrica ``f1-macro`` funciona da seguinte forma:\n",
    "\n",
    "- Precisão = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos) \n",
    "    - De todas as previsões positivas, quantas eram realmente positivas\n",
    "\n",
    "- Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos) \n",
    "    - De todos os casos realmente positivos, quantos foram identificados corretamente\n",
    "\n",
    "A métrica calcula a média harmonica entre a preicisão e o recall:\n",
    "\n",
    "- **F1 = 2 × (Precision × Recall) / (Precision + Recall)**\n",
    "\n",
    "Nela, cada classe tem o mesmo peso, independente de quantos exemplos tenha, o que é útil para o nosso caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f64401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_objetivo(trial, X, y, num_folds, modelo=\"knn\"):\n",
    "    \"\"\"Função objetivo do optuna\"\"\"\n",
    "\n",
    "    if modelo == \"knn\":\n",
    "        modelo = cria_instancia_knn(trial)\n",
    "    elif modelo == \"dtree\":\n",
    "        modelo = cria_instancia_dtree(trial)\n",
    "    elif modelo == \"rf\":\n",
    "        modelo = cria_instancia_rf(trial)\n",
    "    elif modelo == \"lr\":\n",
    "        modelo = cria_instancia_lr(trial)\n",
    "    elif modelo == \"svc\":\n",
    "        modelo = cria_instancia_svc(trial)\n",
    "    \n",
    "    metricas = cross_val_score(\n",
    "        modelo, \n",
    "        X, \n",
    "        y, \n",
    "        scoring=\"f1_macro\",\n",
    "        cv=num_folds,\n",
    "        )\n",
    "    \n",
    "    return metricas.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e9059",
   "metadata": {},
   "source": [
    "### **Otimizando os Hiperparâmetros**\n",
    "\n",
    "A seguir foram criados os estudos (conjunto de trials) usando o ``create_study()``, cujo o argumento ``direction='maximizar'`` tem como objetivo minimizar a [métrica]. Foi o utilizado o ``storage`` para armazenar o progreso da busca e o  ``load_if_exists`` para que seja possível continuar a busca de onde ela parou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d78199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 09:16:04,424] Using an existing study with name 'knn_nanotoxiclogia_optuna' instead of creating a new one.\n",
      "[I 2025-11-03 09:16:04,469] Using an existing study with name 'dtree_nanotoxiclogia_optuna' instead of creating a new one.\n",
      "[I 2025-11-03 09:16:04,677] Using an existing study with name 'svc_nanotoxiclogia_optuna' instead of creating a new one.\n",
      "[I 2025-11-03 09:16:04,714] Using an existing study with name 'rf_nanotoxiclogia_optuna' instead of creating a new one.\n",
      "[I 2025-11-03 09:16:04,747] Using an existing study with name 'lr_nanotoxiclogia_optuna' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "NOME_DO_ESTUDO_KNN = \"knn_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_DTREE = \"dtree_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_SVC = \"svc_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_RF = \"rf_nanotoxiclogia_optuna\"\n",
    "NOME_DO_ESTUDO_LR = \"lr_nanotoxiclogia_optuna\"\n",
    "\n",
    "objeto_de_estudo_knn = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_KNN,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_KNN}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_dtree = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_DTREE,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_DTREE}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_svc = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_SVC,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_SVC}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_rf = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_RF,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_RF}.db\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "objeto_de_estudo_lr = create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=NOME_DO_ESTUDO_LR,\n",
    "    storage=f\"sqlite:///../resultados_optuna/{NOME_DO_ESTUDO_LR}.db\",\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf20fa",
   "metadata": {},
   "source": [
    "Para realmente rodar o otimizador precisamos de uma função objetivo que tenha apenas um argumento, o `trial`. Para isso vamos definir a `funcao_objetivo_parcial`.\n",
    "\n",
    "Serão usados ``modelo='modelo'`` para cada modelo e um número de fols na validação cruzada igual a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27715019",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "\n",
    "def funcao_objetivo_parcial_knn(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"knn\")\n",
    "\n",
    "def funcao_objetivo_parcial_dtree(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"dtree\")\n",
    "\n",
    "def funcao_objetivo_parcial_rf(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"rf\")\n",
    "\n",
    "def funcao_objetivo_parcial_svc(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"svc\")\n",
    "\n",
    "def funcao_objetivo_parcial_lr(trial):\n",
    "    return funcao_objetivo(trial, X_treino, y_treino, NUM_FOLDS, modelo=\"lr\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd3d69",
   "metadata": {},
   "source": [
    "Agora podemos definiro o número de novos trials e rodar cada otimização de modelo separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3622265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 09:16:08,519] Trial 1014 finished with value: 0.8402578592356329 and parameters: {'num_vizinhos': 1, 'pesos': 'uniform', 'tipo_distancia': 1, 'normalizar': True, 'tipo_norm': 'MaxAbs'}. Best is trial 148 with value: 0.8402578592356329.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_knn.optimize(funcao_objetivo_parcial_knn, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4bcc79ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 09:16:09,280] Trial 1011 finished with value: 0.7552768782478383 and parameters: {'profundidade': 378, 'critério': 'entropy', 'min_exemplos_split': 2, 'min_exemplos_folha': 83, 'num_max_features': 0.5453290174242155, 'normalizar': False}. Best is trial 781 with value: 0.8961577595288454.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_dtree.optimize(funcao_objetivo_parcial_dtree, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17a559b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 09:16:12,082] Trial 1412 finished with value: 0.8363184066773817 and parameters: {'C': 605.2164052576776, 'kernel': 'rbf', 'entrada_gamma': 'float', 'gamma': 0.0006509292159462127, 'normalizar': False}. Best is trial 1059 with value: 0.8508233453451532.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_svc.optimize(funcao_objetivo_parcial_svc, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93bf2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 09:16:22,283] Trial 1418 finished with value: 0.8510409801370791 and parameters: {'num_arvores': 572, 'critério': 'log_loss', 'max_depth': 189, 'min_exemplos_split': 13, 'min_exemplos_folha': 5, 'num_max_atributos': 0.12432683735393313, 'normalizar': False}. Best is trial 898 with value: 0.9112519576543396.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 1\n",
    "objeto_de_estudo_rf.optimize(funcao_objetivo_parcial_rf, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f1fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 09:16:39,980] Trial 534 finished with value: 0.7361347729403225 and parameters: {'penalidade': 'elasticnet', 'C': 198.09079207236158, 'l1_ratio': 0.3949838695826708, 'normalizar': True, 'tipo_norm': 'MinMax'}. Best is trial 12 with value: 0.7383435156883571.\n"
     ]
    }
   ],
   "source": [
    "NUM_TENTATIVAS = 0\n",
    "objeto_de_estudo_lr.optimize(funcao_objetivo_parcial_lr, n_trials=NUM_TENTATIVAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fff7d",
   "metadata": {},
   "source": [
    "### **Vizualizando os Resultados**\n",
    "\n",
    "Agora podemos analizar o foi obtido com cada modelo e a partir disso definir qual deles teve o melhor estimativa de resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7355bb",
   "metadata": {},
   "source": [
    "#### **Resultado Dummy (baseline):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b97a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A estimativa do f1-macro para o Dummy foi: 0.4339620717011069\n"
     ]
    }
   ],
   "source": [
    "print(f\"A estimativa do f1-macro para o Dummy foi: {f1_macro_estimativa_dummy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1697cd",
   "metadata": {},
   "source": [
    "#### **Resultado K-NN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4053b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial K-NN: 148\n",
      "Parâmetros do melhor trial : {'num_vizinhos': 1, 'pesos': 'uniform', 'tipo_distancia': 1, 'normalizar': True, 'tipo_norm': 'MaxAbs'}\n",
      "A melhor estimativa do f1-macro para o K-NN foi: 0.8402578592356329\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_knn = objeto_de_estudo_knn.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial K-NN: {melhor_trial_knn.number}\")\n",
    "print(f\"Parâmetros do melhor trial : {melhor_trial_knn.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para o K-NN foi: {objeto_de_estudo_knn.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079f295",
   "metadata": {},
   "source": [
    "#### **Resultado Árvore de Decisão:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18191687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial da Árvore de Decisão: 781\n",
      "Parâmetros do melhor trial da Árvore de Decisão: {'profundidade': 29, 'critério': 'entropy', 'min_exemplos_split': 2, 'min_exemplos_folha': 1, 'num_max_features': 0.4819347463126588, 'normalizar': True, 'tipo_norm': 'MinMax'}\n",
      "A melhor estimativa do f1-macro para a Árvore de Decisão foi: 0.8961577595288454\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_dtree = objeto_de_estudo_dtree.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial da Árvore de Decisão: {melhor_trial_dtree.number}\")\n",
    "print(f\"Parâmetros do melhor trial da Árvore de Decisão: {melhor_trial_dtree.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para a Árvore de Decisão foi: {objeto_de_estudo_dtree.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde835d8",
   "metadata": {},
   "source": [
    "#### **Resultado SVC:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0471ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial do SVC: 1059\n",
      "Parâmetros do melhor trial do SVC: {'C': 992.1950516156445, 'kernel': 'rbf', 'entrada_gamma': 'float', 'gamma': 3.25151263422672e-05, 'normalizar': False}\n",
      "A melhor estimativa do f1-macro para o SVC foi: 0.8508233453451532\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_svc = objeto_de_estudo_svc.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial do SVC: {melhor_trial_svc.number}\")\n",
    "print(f\"Parâmetros do melhor trial do SVC: {melhor_trial_svc.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para o SVC foi: {objeto_de_estudo_svc.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7deaa9c",
   "metadata": {},
   "source": [
    "#### **Resultado Floresta Aleatória:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf58a0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial da Floresta Aleatória: 898\n",
      "Parâmetros do melhor trial da Floresta Aleatória: {'num_arvores': 403, 'critério': 'entropy', 'max_depth': 301, 'min_exemplos_split': 6, 'min_exemplos_folha': 1, 'num_max_atributos': 0.5282007906767744, 'normalizar': False}\n",
      "A melhor estimativa do f1-macro para a Floresta Aletória foi: 0.9112519576543396\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_rf = objeto_de_estudo_rf.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial da Floresta Aleatória: {melhor_trial_rf.number}\")\n",
    "print(f\"Parâmetros do melhor trial da Floresta Aleatória: {melhor_trial_rf.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para a Floresta Aletória foi: {objeto_de_estudo_rf.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73877f5a",
   "metadata": {},
   "source": [
    "#### **Resultado Regressão Logística:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd13676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número do melhor trial da Regressão Logística: 12\n",
      "Parâmetros do melhor trial da Regressão Logística: {'penalidade': 'l1', 'C': 137.97053160889004, 'normalizar': True, 'tipo_norm': 'MinMax'}\n",
      "A melhor estimativa do f1-macro para a Regressão Logística foi: 0.7383435156883571\n"
     ]
    }
   ],
   "source": [
    "melhor_trial_lr = objeto_de_estudo_lr.best_trial\n",
    "\n",
    "print(f\"Número do melhor trial da Regressão Logística: {melhor_trial_lr.number}\")\n",
    "print(f\"Parâmetros do melhor trial da Regressão Logística: {melhor_trial_lr.params}\")\n",
    "print(f\"A melhor estimativa do f1-macro para a Regressão Logística foi: {objeto_de_estudo_lr.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319dac1b",
   "metadata": {},
   "source": [
    "### **Conclusão sobre esse notebook**\n",
    "\n",
    "Neste notebook, implementamos e otimizamos diversos modelos de aprendizado de máquina para prever a toxicidade de nanopartículas com base em suas características físico-químicas e condições experimentais. Utilizamos técnicas como agrupamento de dados para evitar vazamento, codificação one-hot para variáveis categóricas e validação cruzada para garantir a qualidade das métricas.\n",
    "\n",
    "Os modelos foram otimizados com o Optuna, que permitiu encontrar combinações de hiperparâmetros que maximizassem a estimativa do F1-score macro.\n",
    "\n",
    "| Modelo               |   F1-Macro |   Melhor Trial |\n",
    "|----------------------|------------|----------------|\n",
    "| Baseline             |     0.4339 |              - |\n",
    "| K-NN                 |     0.8402 |            148 |\n",
    "| Árvore de Decisão    |     0.8961 |            781 |\n",
    "| SVC                  |     0.8508 |           1059 |\n",
    "| Floresta Aleatória   |     0.9112 |            898 |\n",
    "| Regressão Logística  |     0.7383 |             12 |\n",
    "\n",
    "A principio foi possível observar que:\n",
    "\n",
    "Todos os modelos superaram significativamente o baseline, mostrando que as features utilizadas possuem um valor preditivo. Além disso, modelos como Floresta Aleatória e a Árvore de Decisão tiveram um melhor resultado.\n",
    "\n",
    "O avaliação desses modelos nos dados de teste pode ser vista no arquivo **``notebooks\\avaliacao_modelos.ipynb``**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
